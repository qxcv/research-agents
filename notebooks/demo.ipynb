{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import research_agents.arxiv_download as adl\n",
    "import research_agents.html_to_ref_list as h2rl\n",
    "import research_agents.summarize as summ\n",
    "import anthropic\n",
    "from IPython.display import display, HTML\n",
    "from html import escape\n",
    "from research_agents.get_relevant_papers import get_relevant_papers\n",
    "from research_agents.prophy_scrape import download_prophy\n",
    "\n",
    "\n",
    "arxiv_url = 'https://arxiv.org/abs/2004.04136'\n",
    "# stop_len = 'Number of comparison papers to filter'\n",
    "\n",
    "display(HTML(\"<h2>Thinking...</h2>\"))\n",
    "\n",
    "# Declare client \n",
    "api_file = open(\"api_key.txt\", \"r\")\n",
    "api_key = api_file.read()\n",
    "client = anthropic.Client(api_key)\n",
    "\n",
    "# Arxiv URL to html\n",
    "display(HTML(f'<p>Downloading <a href=\"{escape(arxiv_url)}\" target=_blank><code>{escape(arxiv_url)}</code></a></p>'))\n",
    "html = adl.download_arxiv_html(arxiv_url)\n",
    "\n",
    "# Prompt prophy for candidate reference papers (title + authors + abstract)\n",
    "title_original, abstract_original, citing_data = download_prophy(arxiv_url)\n",
    "title_refs = [d['title'] for d in citing_data]\n",
    "abstract_refs = [d['abstract'] for d in citing_data]\n",
    "arxivids_refs = [d['arxiv'] for d in citing_data]\n",
    "\n",
    "# Filter out papers that are not relevant\n",
    "stop_len = 3\n",
    "good_idxs = get_relevant_papers(client, title_original, abstract_original, title_refs, abstract_refs, stop_len)\n",
    "title_refs = [title_refs[i] for i in good_idxs]\n",
    "abstract_refs = [abstract_refs[i] for i in good_idxs]\n",
    "arxivids_refs = [arxivids_refs[i] for i in good_idxs]\n",
    "\n",
    "print(f'Number of relevant follow-ups: {len(title_refs)}')\n",
    "\n",
    "responses = []\n",
    "for i, (ref_title, ref_abstract) in enumerate(zip(title_refs, abstract_refs)):\n",
    "    # For each relevant paper, extract snippets that mention the original paper\n",
    "\n",
    "    # print(f'Reference title: {ref_title}')\n",
    "    ref_html = adl.download_arxiv_html(arxivids_refs[i])\n",
    "\n",
    "    responses.append(summ.summarize_differences(client, html, ref_html))\n",
    "\n",
    "# Summarize all the summaries in a single paragraph\n",
    "meta_summary = summ.make_meta_summary(client=client, responses=responses, title_original=title_original)\n",
    "\n",
    "print(meta_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
